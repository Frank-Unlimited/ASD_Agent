/**
 * AI è§†é¢‘é€šè¯ç»„ä»¶
 * ä½¿ç”¨ Qwen-Omni-Realtime å®ç°å®æ—¶è§†é¢‘é€šè¯å’Œè¡Œä¸ºè§‚å¯Ÿ
 */

import React, { useState, useRef, useEffect } from 'react';
import { Camera, Mic, MicOff, Video, VideoOff, X, Activity, Lightbulb, AlertCircle, Maximize2, Minimize2, GripVertical } from 'lucide-react';
import { motion, AnimatePresence } from 'framer-motion';
import { qwenRealtimeService } from '../services/qwenRealtimeService';
import { ChildProfile, FloorGame } from '../types';
import { floorGameStorageService } from '../services/floorGameStorage';
import { collectVideoCallContext } from '../services/videoCallContextHelper';

interface AIVideoCallProps {
  childProfile: ChildProfile | null;
  gameData?: FloorGame | null; // æ”¹ä¸ºå¯é€‰
  gameId?: string; // å½“å‰æ¸¸æˆçš„ IDï¼Œç”¨äºä¿å­˜èŠå¤©è®°å½•
  onClose: () => void;
  isInline?: boolean; // æ–°å¢ï¼šæ˜¯å¦åµŒå…¥å¼æ˜¾ç¤ºï¼ˆéå…¨å±ï¼‰
}

/**
 * è®¡ç®—å¹´é¾„
 */
const calculateAge = (birthDate: string): number => {
  const birth = new Date(birthDate);
  const today = new Date();
  let age = today.getFullYear() - birth.getFullYear();
  const monthDiff = today.getMonth() - birth.getMonth();
  if (monthDiff < 0 || (monthDiff === 0 && today.getDate() < birth.getDate())) {
    age--;
  }
  return age;
};

const AIVideoCall: React.FC<AIVideoCallProps> = ({
  childProfile,
  gameData,
  gameId,
  onClose,
  isInline = false
}) => {
  const [isActive, setIsActive] = useState(false);
  const [isConnecting, setIsConnecting] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [isVideoEnabled, setIsVideoEnabled] = useState(true);
  const [isMinimized, setIsMinimized] = useState(false);
  const [isFullScreen, setIsFullScreen] = useState(false);
  const [userTranscript, setUserTranscript] = useState(''); // å½“å‰ç”¨æˆ·è¯´çš„è¯
  const [assistantTranscript, setAssistantTranscript] = useState(''); // å½“å‰ AI è¯´çš„è¯
  const [suggestions, setSuggestions] = useState<string[]>([]);
  const [isSpeaking, setIsSpeaking] = useState(false);

  // èŠå¤©å†å²è®°å½•ï¼ˆé¢„ç•™ï¼Œç”¨äºåç»­å­˜å‚¨ï¼‰
  const conversationHistoryRef = useRef<Array<{
    role: 'user' | 'assistant';
    content: string;
    timestamp: number;
  }>>([]);

  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const audioWorkletNodeRef = useRef<AudioWorkletNode | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const frameIntervalRef = useRef<number | null>(null);
  const audioPlayerRef = useRef<AudioContext | null>(null);
  const audioQueueRef = useRef<ArrayBuffer[]>([]);
  const isPlayingRef = useRef(false);
  const isMutedRef = useRef(false); // ä½¿ç”¨ ref é¿å…é—­åŒ…é—®é¢˜
  const currentAudioSourceRef = useRef<AudioBufferSourceNode | null>(null); // å½“å‰æ’­æ”¾çš„éŸ³é¢‘æº

  /**
   * å¯åŠ¨è§†é¢‘é€šè¯
   */
  const startCall = async () => {
    try {
      setIsConnecting(true);

      // 1. è·å–æ‘„åƒå¤´å’Œéº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 720, height: 480, frameRate: 30 },
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      });

      mediaStreamRef.current = stream;

      // 2. æ˜¾ç¤ºè§†é¢‘é¢„è§ˆ
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }

      // 3. æ”¶é›†å®Œæ•´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
      console.log('[AI Video Call] æ”¶é›†ä¸Šä¸‹æ–‡ä¿¡æ¯...');
      const contextData = await collectVideoCallContext(childProfile, gameData || null);
      console.log('[AI Video Call] ä¸Šä¸‹æ–‡ä¿¡æ¯:', contextData);

      // 4. è¿æ¥åˆ° Qwen-Omni-Realtimeï¼ˆä½¿ç”¨å®˜æ–¹ Python SDKï¼‰
      await qwenRealtimeService.connect({
        onConnected: () => {
          console.log('[AI Video Call] å·²è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œç­‰å¾…ä¼šè¯åˆå§‹åŒ–...');
        },
        onSessionCreated: () => {
          console.log('[AI Video Call] ä¼šè¯å·²åˆå§‹åŒ–ï¼Œå¼€å§‹éŸ³è§†é¢‘é‡‡é›†');
          setIsActive(true);
          setIsConnecting(false);

          // å¼€å§‹éŸ³é¢‘é‡‡é›†
          startAudioCapture(stream);

          // å¯åŠ¨è§†é¢‘å¸§é‡‡é›†ï¼ˆæ¯1ç§’ä¸€å¸§ï¼‰
          startFrameCapture();
        },
        onSessionUpdated: () => {
          console.log('[AI Video Call] ä¼šè¯é…ç½®å·²æ›´æ–°');
        },
        onDisconnected: () => {
          console.log('[AI Video Call] è¿æ¥å·²æ–­å¼€');
          stopCall();
        },
        onError: (error) => {
          console.error('[AI Video Call] é”™è¯¯:', error);
          alert('è¿æ¥å¤±è´¥ï¼š' + error.message);
          stopCall();
        },
        onUserTranscript: (transcript) => {
          console.log('[AI Video Call] ğŸ“ æ”¶åˆ°ç”¨æˆ·è½¬å½•:', transcript);
          // æ˜¾ç¤ºç”¨æˆ·å½“å‰è¯´çš„è¯
          setUserTranscript(transcript);

          // ä¿å­˜åˆ°å†å²è®°å½•
          conversationHistoryRef.current.push({
            role: 'user',
            content: transcript,
            timestamp: Date.now()
          });
          console.log('[AI Video Call] âœ… ç”¨æˆ·æ¶ˆæ¯å·²ä¿å­˜åˆ°å†å²è®°å½•ï¼Œå½“å‰æ€»æ•°:', conversationHistoryRef.current.length);
        },
        onAssistantTranscript: (delta) => {
          // ç´¯ç§¯å½“å‰è¿™ä¸€è½® AI çš„å›å¤
          setAssistantTranscript(prev => prev + delta);

          // æ£€æŸ¥æ˜¯å¦åŒ…å«å»ºè®®
          if (delta.includes('å»ºè®®') || delta.includes('å¯ä»¥') || delta.includes('è¯•è¯•')) {
            // æå–å»ºè®®ï¼ˆç®€å•å®ç°ï¼‰
            const sentences = (assistantTranscript + delta).split(/[ã€‚ï¼ï¼Ÿ]/);
            const newSuggestions = sentences.filter(s =>
              s.includes('å»ºè®®') || s.includes('å¯ä»¥') || s.includes('è¯•è¯•')
            ).slice(-3);
            setSuggestions(newSuggestions);
          }
        },
        onAssistantAudio: (audioData) => {
          // æ’­æ”¾éŸ³é¢‘
          playAudio(audioData);
        },
        onSpeechStarted: () => {
          setIsSpeaking(true);

          // ç”¨æˆ·å¼€å§‹è¯´è¯ï¼Œæ¸…ç©ºå½“å‰æ˜¾ç¤ºçš„ç”¨æˆ·æ–‡æœ¬ï¼ˆå‡†å¤‡æ˜¾ç¤ºæ–°çš„ï¼‰
          setUserTranscript('');

          // æ‰“æ–­ AIï¼šåœæ­¢å½“å‰æ’­æ”¾çš„éŸ³é¢‘
          if (currentAudioSourceRef.current) {
            try {
              currentAudioSourceRef.current.stop();
              currentAudioSourceRef.current = null;
              console.log('[AI Video Call] ç”¨æˆ·æ‰“æ–­ï¼Œåœæ­¢ AI éŸ³é¢‘æ’­æ”¾');
            } catch (e) {
              // éŸ³é¢‘å¯èƒ½å·²ç»åœæ­¢ï¼Œå¿½ç•¥é”™è¯¯
            }
          }

          // æ¸…ç©ºéŸ³é¢‘é˜Ÿåˆ—
          audioQueueRef.current = [];
          isPlayingRef.current = false;
        },
        onSpeechStopped: () => {
          setIsSpeaking(false);
        },
        onResponseStarted: () => {
          // AI å¼€å§‹æ–°çš„å›å¤ï¼Œæ¸…ç©ºä¸Šä¸€è½®çš„æ–‡æœ¬å’ŒéŸ³é¢‘
          console.log('[AI Video Call] AI å¼€å§‹æ–°çš„å›å¤ï¼Œæ¸…ç©ºä¸Šä¸€è½®æ–‡æœ¬å’ŒéŸ³é¢‘');
          setAssistantTranscript('');

          // åœæ­¢å½“å‰æ’­æ”¾çš„éŸ³é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
          if (currentAudioSourceRef.current) {
            try {
              currentAudioSourceRef.current.stop();
              currentAudioSourceRef.current = null;
              console.log('[AI Video Call] åœæ­¢ä¸Šä¸€è½® AI éŸ³é¢‘æ’­æ”¾');
            } catch (e) {
              // éŸ³é¢‘å¯èƒ½å·²ç»åœæ­¢ï¼Œå¿½ç•¥é”™è¯¯
            }
          }

          // æ¸…ç©ºéŸ³é¢‘é˜Ÿåˆ—ï¼Œå‡†å¤‡æ’­æ”¾æ–°çš„å›å¤
          audioQueueRef.current = [];
          isPlayingRef.current = false;
        },
        onResponseCompleted: (fullTranscript) => {
          // AI å›å¤å®Œæˆï¼Œä¿å­˜åˆ°å†å²è®°å½•
          if (fullTranscript) {
            conversationHistoryRef.current.push({
              role: 'assistant',
              content: fullTranscript,
              timestamp: Date.now()
            });
            console.log('[AI Video Call] âœ… AI æ¶ˆæ¯å·²ä¿å­˜åˆ°å†å²è®°å½•ï¼Œå½“å‰æ€»æ•°:', conversationHistoryRef.current.length);
          } else {
            console.warn('[AI Video Call] âš ï¸  AI å›å¤å®Œæˆä½†æ–‡æœ¬ä¸ºç©º');
          }
        }
      }, contextData);

    } catch (error) {
      console.error('[AI Video Call] å¯åŠ¨å¤±è´¥:', error);
      alert('æ— æ³•è®¿é—®æ‘„åƒå¤´æˆ–éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®');
      setIsConnecting(false);
    }
  };
  /**
   * å¯åŠ¨éŸ³é¢‘é‡‡é›†ï¼ˆå®Œå…¨å¤åˆ¶å®˜æ–¹ SDK è¡Œä¸ºï¼‰
   */
  const startAudioCapture = async (stream: MediaStream) => {
    try {
      // ä½¿ç”¨ 16kHz é‡‡æ ·ç‡ï¼ˆä¸å®˜æ–¹ SDK ä¸€è‡´ï¼‰
      audioContextRef.current = new AudioContext({ sampleRate: 16000 });
      const source = audioContextRef.current.createMediaStreamSource(stream);

      // åˆ›å»º ScriptProcessorNode
      // å®˜æ–¹ SDK ä½¿ç”¨ 3200 ä¸ªæ ·æœ¬ï¼ˆ6400 å­—èŠ‚ï¼‰ï¼Œä½† ScriptProcessorNode åªæ”¯æŒ 2 çš„å¹‚æ¬¡
      // å°è¯•ä½¿ç”¨ 4096 æ ·æœ¬ï¼ˆ8192 å­—èŠ‚ï¼Œæ›´æ¥è¿‘å®˜æ–¹çš„ 6400 å­—èŠ‚ï¼‰
      const processor = audioContextRef.current.createScriptProcessor(4096, 1, 1);

      console.log('[AI Video Call] éŸ³é¢‘é‡‡é›†å·²å¯åŠ¨ - é‡‡æ ·ç‡:', audioContextRef.current.sampleRate, 'Hz, ç¼“å†²åŒº:', 4096, 'æ ·æœ¬ (256ms)');

      let packetCount = 0;
      let isSpeaking = false;
      let silenceFrames = 0;
      let speechFrames = 0; // è¿ç»­è¯­éŸ³å¸§è®¡æ•°
      const SPEECH_THRESHOLD = 0.05; // è¯­éŸ³æ£€æµ‹é˜ˆå€¼
      const SPEECH_FRAMES_THRESHOLD = 3; // éœ€è¦è¿ç»­ 3 å¸§è¶…è¿‡é˜ˆå€¼æ‰è®¤ä¸ºæ˜¯è¯­éŸ³ï¼ˆçº¦ 0.75 ç§’ï¼‰
      const SILENCE_FRAMES_THRESHOLD = 4; // é™éŸ³å¸§æ•°é˜ˆå€¼ï¼ˆçº¦ 1 ç§’ï¼‰

      processor.onaudioprocess = (e) => {
        if (!isMutedRef.current && qwenRealtimeService.isConnectionActive()) {
          const inputData = e.inputBuffer.getChannelData(0);

          // æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®éŸ³é¢‘æ•°æ®ï¼ˆä¸æ˜¯å…¨ 0ï¼‰
          let hasAudio = false;
          let maxAmplitude = 0;
          for (let i = 0; i < inputData.length; i++) {
            const abs = Math.abs(inputData[i]);
            if (abs > maxAmplitude) maxAmplitude = abs;
            if (abs > 0.001) {
              hasAudio = true;
            }
          }

          // æ”¹è¿›çš„ VAD æ£€æµ‹ï¼šéœ€è¦è¿ç»­å¤šå¸§è¶…è¿‡é˜ˆå€¼æ‰è®¤ä¸ºæ˜¯è¯­éŸ³
          const isSpeechDetected = maxAmplitude > SPEECH_THRESHOLD;

          if (isSpeechDetected) {
            speechFrames++;
            silenceFrames = 0;

            // éœ€è¦è¿ç»­å¤šå¸§è¶…è¿‡é˜ˆå€¼æ‰è§¦å‘è¯­éŸ³å¼€å§‹
            if (!isSpeaking && speechFrames >= SPEECH_FRAMES_THRESHOLD) {
              console.log('[AI Video Call] ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ (æŒ¯å¹…:', maxAmplitude.toFixed(3), ')');
              qwenRealtimeService.sendMessage({ type: 'speech_start' });
              isSpeaking = true;
            }
          } else {
            speechFrames = 0; // é‡ç½®è¯­éŸ³å¸§è®¡æ•°

            if (isSpeaking) {
              silenceFrames++;
              if (silenceFrames >= SILENCE_FRAMES_THRESHOLD) {
                console.log('[AI Video Call] ğŸ”‡ æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼Œè‡ªåŠ¨æäº¤');
                qwenRealtimeService.sendMessage({ type: 'speech_end' });
                qwenRealtimeService.sendMessage({ type: 'commit' });
                isSpeaking = false;
                silenceFrames = 0;
              }
            }
          }

          // è·³è¿‡é™éŸ³åŒ…ï¼ˆå‰å‡ ä¸ªåŒ…å¯èƒ½å…¨æ˜¯é™éŸ³ï¼‰
          if (!hasAudio) {
            if (packetCount < 3) {
              console.log(`[AI Video Call] è·³è¿‡é™éŸ³åŒ… #${packetCount + 1}`);
              packetCount++;
            }
            return;
          }

          // åªåœ¨å‰ 3 ä¸ªåŒ…æ‰“å°è¯¦ç»†æ—¥å¿—
          if (packetCount < 3) {
            console.log(`[AI Video Call] åŸå§‹éŸ³é¢‘æ•°æ® #${packetCount + 1}:`, {
              hasAudio,
              maxAmplitude: maxAmplitude.toFixed(6),
              length: inputData.length,
              first10: Array.from(inputData.slice(0, 10)),
              // æ‰¾åˆ°ç¬¬ä¸€ä¸ªéé›¶å€¼çš„ä½ç½®
              firstNonZeroIndex: Array.from(inputData).findIndex(v => Math.abs(v) > 0.001),
              // æ˜¾ç¤ºæœ€å¤§æŒ¯å¹…é™„è¿‘çš„å€¼
              maxIndex: Array.from(inputData).findIndex(v => Math.abs(v) === maxAmplitude)
            });
          }

          // è½¬æ¢ä¸º Int16Array (PCM16)
          const pcm16 = new Int16Array(inputData.length);
          for (let i = 0; i < inputData.length; i++) {
            // é™åˆ¶åœ¨ [-1, 1] èŒƒå›´å†…
            const s = Math.max(-1, Math.min(1, inputData[i]));
            // è½¬æ¢ä¸º 16-bit æ•´æ•°
            pcm16[i] = s < 0 ? Math.floor(s * 0x8000) : Math.floor(s * 0x7FFF);
          }

          // æ£€æŸ¥å‰é¢çš„å­—èŠ‚æ˜¯å¦å…¨æ˜¯ 0ï¼ˆé˜¿é‡Œäº‘å¯èƒ½ä¸æ¥å—å‰é¢å…¨æ˜¯ 0 çš„åŒ…ï¼‰
          const firstBytes = new Uint8Array(pcm16.buffer.slice(0, 20));
          const hasDataAtStart = Array.from(firstBytes).some(b => b !== 0);

          if (!hasDataAtStart) {
            if (packetCount < 3) {
              console.log(`[AI Video Call] è·³è¿‡å‰é¢å…¨æ˜¯ 0 çš„éŸ³é¢‘åŒ… #${packetCount + 1}`);
              packetCount++;
            }
            return;
          }

          // åªåœ¨å‰ 3 ä¸ªåŒ…æ‰“å°æ—¥å¿—
          if (packetCount < 3) {
            // æ‰¾åˆ°æœ€å¤§æŒ¯å¹…çš„ä½ç½®
            const maxIndex = Array.from(inputData).findIndex(v => Math.abs(v) === maxAmplitude);

            console.log(`[AI Video Call] è½¬æ¢åçš„ PCM16 æ•°æ® #${packetCount + 1}:`, {
              samples: pcm16.length,
              bytes: pcm16.buffer.byteLength,
              first10: Array.from(pcm16.slice(0, 10)),
              // æ˜¾ç¤ºæœ€å¤§æŒ¯å¹…é™„è¿‘çš„è½¬æ¢ç»“æœ
              aroundMaxIndex: maxIndex >= 0 ? {
                index: maxIndex,
                originalValue: inputData[maxIndex],
                convertedValue: pcm16[maxIndex],
                nearby: Array.from(pcm16.slice(Math.max(0, maxIndex - 5), maxIndex + 5))
              } : null,
              bufferFirst20Bytes: Array.from(new Uint8Array(pcm16.buffer.slice(0, 20))),
              // æ˜¾ç¤ºæœ€å¤§æŒ¯å¹…ä½ç½®çš„å­—èŠ‚
              bufferAroundMax: maxIndex >= 0 ? Array.from(new Uint8Array(pcm16.buffer.slice(maxIndex * 2, maxIndex * 2 + 10))) : null
            });
            packetCount++;
          }

          // å‘é€åˆ°æœåŠ¡å™¨
          qwenRealtimeService.sendAudio(pcm16.buffer);
        }
      };

      // é‡è¦ï¼šå¿…é¡»è¿æ¥åˆ° destinationï¼Œå¦åˆ™ä¸ä¼šè§¦å‘ onaudioprocess
      source.connect(processor);
      processor.connect(audioContextRef.current.destination);

    } catch (error) {
      console.error('[AI Video Call] éŸ³é¢‘é‡‡é›†å¤±è´¥:', error);
    }
  };

  /**
   * å¯åŠ¨è§†é¢‘å¸§é‡‡é›†
   */
  const startFrameCapture = () => {
    frameIntervalRef.current = window.setInterval(() => {
      if (!isVideoEnabled || !videoRef.current || !canvasRef.current) return;

      const video = videoRef.current;
      const canvas = canvasRef.current;
      const context = canvas.getContext('2d');

      if (!context || video.readyState !== video.HAVE_ENOUGH_DATA) return;

      // è®¾ç½® canvas å°ºå¯¸
      canvas.width = 720;
      canvas.height = 480;

      // ç»˜åˆ¶å½“å‰å¸§
      context.drawImage(video, 0, 0, canvas.width, canvas.height);

      // è½¬æ¢ä¸º JPEG base64ï¼ˆä½†ä¸ç«‹å³å‘é€ï¼Œç­‰å¾…éŸ³é¢‘å‘é€æ—¶ä¸€èµ·å‘é€ï¼‰
      canvas.toBlob((blob) => {
        if (blob) {
          const reader = new FileReader();
          reader.onloadend = () => {
            const base64 = reader.result as string;
            // åªæœ‰åœ¨è¿æ¥æ´»è·ƒæ—¶æ‰å‘é€
            if (qwenRealtimeService.isConnectionActive()) {
              qwenRealtimeService.sendImage(base64);
            }
          };
          reader.readAsDataURL(blob);
        }
      }, 'image/jpeg', 0.6); // é™ä½è´¨é‡åˆ° 0.6ï¼Œå‡å°‘æ•°æ®é‡

    }, 3000); // æ”¹ä¸ºæ¯3ç§’ä¸€å¸§ï¼Œè¿›ä¸€æ­¥é™ä½é¢‘ç‡
  };

  /**
   * æ’­æ”¾éŸ³é¢‘
   */
  const playAudio = async (audioData: ArrayBuffer) => {
    audioQueueRef.current.push(audioData);

    if (!isPlayingRef.current) {
      isPlayingRef.current = true;
      await processAudioQueue();
    }
  };

  /**
   * å¤„ç†éŸ³é¢‘é˜Ÿåˆ—
   */
  const processAudioQueue = async () => {
    // ç¡®ä¿ AudioContext å­˜åœ¨
    if (!audioPlayerRef.current || audioPlayerRef.current.state === 'closed') {
      try {
        audioPlayerRef.current = new AudioContext({ sampleRate: 24000 });
        console.log('[AI Video Call] åˆ›å»ºæ–°çš„ AudioContext');
      } catch (error) {
        console.error('[AI Video Call] æ— æ³•åˆ›å»º AudioContext:', error);
        isPlayingRef.current = false;
        return;
      }
    }

    while (audioQueueRef.current.length > 0) {
      const audioData = audioQueueRef.current.shift();
      if (!audioData) continue;

      try {
        // å†æ¬¡æ£€æŸ¥ AudioContextï¼ˆå¯èƒ½åœ¨å¾ªç¯ä¸­è¢«å…³é—­ï¼‰
        if (!audioPlayerRef.current || audioPlayerRef.current.state === 'closed') {
          console.warn('[AI Video Call] AudioContext å·²å…³é—­ï¼Œåœæ­¢æ’­æ”¾');
          break;
        }

        // é˜¿é‡Œäº‘è¿”å›çš„æ˜¯ PCM16 æ ¼å¼ï¼ˆ16-bit, 24kHz, å•å£°é“ï¼‰
        const audioBuffer = audioPlayerRef.current.createBuffer(
          1, // å•å£°é“
          audioData.byteLength / 2, // PCM16 æ¯ä¸ªæ ·æœ¬2å­—èŠ‚
          24000 // é‡‡æ ·ç‡
        );

        const channelData = audioBuffer.getChannelData(0);
        const view = new DataView(audioData);

        for (let i = 0; i < channelData.length; i++) {
          // è¯»å–2å­—èŠ‚çš„PCM16æ•°æ®ï¼ˆå°ç«¯åºï¼‰
          const sample = view.getInt16(i * 2, true);

          // å½’ä¸€åŒ–åˆ° [-1, 1]
          channelData[i] = sample / 32768.0;
        }

        // æ’­æ”¾
        const source = audioPlayerRef.current.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioPlayerRef.current.destination);

        // ä¿å­˜å½“å‰éŸ³é¢‘æºï¼Œä»¥ä¾¿ç”¨æˆ·æ‰“æ–­æ—¶åœæ­¢
        currentAudioSourceRef.current = source;

        source.start();

        // ç­‰å¾…æ’­æ”¾å®Œæˆ
        await new Promise(resolve => {
          source.onended = () => {
            currentAudioSourceRef.current = null; // æ’­æ”¾å®Œæˆï¼Œæ¸…ç©ºå¼•ç”¨
            resolve(null);
          };
        });

      } catch (error) {
        console.error('[AI Video Call] éŸ³é¢‘æ’­æ”¾å¤±è´¥:', error);
        // ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªéŸ³é¢‘
      }
    }

    isPlayingRef.current = false;
  };

  /**
   * å…³é—­ç»„ä»¶ï¼ˆæ¸…ç†èµ„æºå¹¶é€šçŸ¥çˆ¶ç»„ä»¶ï¼‰
   */
  const handleClose = () => {
    // å…ˆåœæ­¢é€šè¯ï¼Œæ¸…ç†æ‰€æœ‰èµ„æº
    if (isActive) {
      stopCall();
    }

    // é€šçŸ¥çˆ¶ç»„ä»¶å…³é—­
    onClose();
  };

  /**
   * åœæ­¢é€šè¯
   */
  const stopCall = () => {
    // ä¿å­˜èŠå¤©è®°å½•åˆ°æ¸¸æˆæ•°æ®
    console.log('[AI Video Call] å‡†å¤‡ä¿å­˜èŠå¤©è®°å½•...');
    console.log('[AI Video Call] gameId:', gameId);
    console.log('[AI Video Call] å†å²è®°å½•æ•°é‡:', conversationHistoryRef.current.length);
    console.log('[AI Video Call] å†å²è®°å½•å†…å®¹:', conversationHistoryRef.current);

    if (gameId && conversationHistoryRef.current.length > 0) {
      try {
        const chatHistory = JSON.stringify(conversationHistoryRef.current);
        console.log('[AI Video Call] åºåˆ—åŒ–åçš„èŠå¤©è®°å½•:', chatHistory);

        floorGameStorageService.updateGame(gameId, {
          chat_history_in_game: chatHistory
        });
        console.log('[AI Video Call] âœ… èŠå¤©è®°å½•å·²ä¿å­˜åˆ°æ¸¸æˆæ•°æ®:', gameId);
      } catch (error) {
        console.error('[AI Video Call] âŒ ä¿å­˜èŠå¤©è®°å½•å¤±è´¥:', error);
      }
    } else {
      if (!gameId) {
        console.warn('[AI Video Call] âš ï¸  æœªæä¾› gameIdï¼Œæ— æ³•ä¿å­˜èŠå¤©è®°å½•');
      }
      if (conversationHistoryRef.current.length === 0) {
        console.warn('[AI Video Call] âš ï¸  èŠå¤©è®°å½•ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜');
      }
    }

    // åœæ­¢å¸§é‡‡é›†
    if (frameIntervalRef.current) {
      clearInterval(frameIntervalRef.current);
      frameIntervalRef.current = null;
    }

    // åœæ­¢éŸ³é¢‘ä¸Šä¸‹æ–‡
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    if (audioPlayerRef.current) {
      audioPlayerRef.current.close();
      audioPlayerRef.current = null;
    }

    // åœæ­¢åª’ä½“æµ
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }

    // æ–­å¼€æœåŠ¡
    qwenRealtimeService.disconnect();

    setIsActive(false);
    setIsConnecting(false);
    setUserTranscript('');
    setAssistantTranscript('');
  };

  /**
   * è·å–èŠå¤©å†å²è®°å½•ï¼ˆé¢„ç•™æ¥å£ï¼‰
   * å¯ç”¨äºåç»­ä¿å­˜åˆ°æ•°æ®åº“æˆ–å¯¼å‡º
   */
  const getConversationHistory = () => {
    return conversationHistoryRef.current;
  };

  /**
   * åˆ‡æ¢é™éŸ³
   */
  const toggleMute = () => {
    setIsMuted(prev => {
      const newMuted = !prev;
      isMutedRef.current = newMuted; // åŒæ­¥æ›´æ–° ref
      console.log('[AI Video Call] éº¦å…‹é£çŠ¶æ€åˆ‡æ¢:', prev ? 'é™éŸ³' : 'å¼€å¯', '->', newMuted ? 'é™éŸ³' : 'å¼€å¯');
      return newMuted;
    });
  };

  /**
   * åˆ‡æ¢è§†é¢‘
   */
  const toggleVideo = () => {
    setIsVideoEnabled(prev => {
      const newEnabled = !prev;
      console.log('[AI Video Call] è§†é¢‘çŠ¶æ€åˆ‡æ¢:', prev ? 'å¼€å¯' : 'å…³é—­', '->', newEnabled ? 'å¼€å¯' : 'å…³é—­');

      if (videoRef.current && videoRef.current.srcObject) {
        const stream = videoRef.current.srcObject as MediaStream;
        stream.getVideoTracks().forEach(track => {
          track.enabled = newEnabled;
        });
      }

      return newEnabled;
    });
  };

  /**
   * è®¡ç®—å¹´é¾„
   */
  const calculateAge = (birthDate: string): number => {
    const today = new Date();
    const birth = new Date(birthDate);
    let age = today.getFullYear() - birth.getFullYear();
    const monthDiff = today.getMonth() - birth.getMonth();
    if (monthDiff < 0 || (monthDiff === 0 && today.getDate() < birth.getDate())) {
      age--;
    }
    return age;
  };

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return () => {
      if (isActive) {
        stopCall();
      }
    };
  }, [isActive]);

  const windowVariants = {
    floating: {
      width: '280px',
      height: '380px',
      bottom: '100px',
      right: '16px',
      borderRadius: '24px',
      transition: { type: 'spring' as const, damping: 25, stiffness: 200 }
    },
    full: {
      width: '100vw',
      height: '100vh',
      bottom: '0px',
      right: '0px',
      borderRadius: '0px',
      transition: { type: 'spring' as const, damping: 25, stiffness: 200 }
    }
  };

  return (
    <motion.div
      initial="floating"
      animate={isFullScreen ? "full" : "floating"}
      variants={windowVariants}
      drag={!isFullScreen}
      dragConstraints={{ left: -300, right: 0, top: -500, bottom: 0 }}
      dragElastic={0.1}
      dragMomentum={false}
      className="fixed z-[60] bg-black shadow-[0_20px_50px_rgba(0,0,0,0.3)] overflow-hidden flex flex-col border border-white/10 backdrop-blur-xl"
    >
      {/* Video Content */}
      <div className="relative flex-1 bg-gray-900 overflow-hidden">
        <video
          ref={videoRef}
          autoPlay
          playsInline
          muted
          className="w-full h-full object-cover"
        />

        {/* Hidden canvas for frame capture */}
        <canvas ref={canvasRef} className="hidden" />

        {/* Glassmorphic Overlays */}
        <div className="absolute top-4 left-4 right-4 flex justify-between items-start pointer-events-none">
          {/* Status Badge */}
          <div className="flex flex-col space-y-2 pointer-events-auto">
            <div className={`px-3 py-1.5 rounded-full text-[10px] font-bold flex items-center backdrop-blur-md border border-white/20 ${isActive ? 'bg-green-500/80' : isConnecting ? 'bg-yellow-500/80' : 'bg-gray-500/80'} text-white shadow-lg`}>
              <div className={`w-2 h-2 rounded-full mr-2 ${isActive ? 'bg-white animate-pulse' : 'bg-white/50'}`} />
              {isActive ? 'AI è§‚å¯Ÿä¸­' : isConnecting ? 'è¿æ¥ä¸­...' : 'å‡†å¤‡å°±ç»ª'}
            </div>

            {isSpeaking && (
              <motion.div
                initial={{ opacity: 0, x: -10 }}
                animate={{ opacity: 1, x: 0 }}
                className="px-3 py-1.5 rounded-full text-[10px] font-bold bg-blue-500/80 text-white flex items-center backdrop-blur-md border border-white/20 shadow-lg"
              >
                <div className="flex space-x-0.5 mr-2">
                  <div className="w-1 h-3 bg-white rounded-full animate-[bounce_1s_infinite_0s]" />
                  <div className="w-1 h-4 bg-white rounded-full animate-[bounce_1s_infinite_0.2s]" />
                  <div className="w-1 h-3 bg-white rounded-full animate-[bounce_1s_infinite_0.4s]" />
                </div>
                å¬å–ä¸­
              </motion.div>
            )}
          </div>

          {/* Window Controls */}
          <div className="flex space-x-2 pointer-events-auto">
            <button
              onClick={() => setIsFullScreen(!isFullScreen)}
              className="p-2 rounded-full bg-black/30 hover:bg-black/50 text-white backdrop-blur-md border border-white/10 transition-all active:scale-95"
            >
              {isFullScreen ? <Minimize2 className="w-4 h-4" /> : <Maximize2 className="w-4 h-4" />}
            </button>
            <button
              onClick={handleClose}
              className="p-2 rounded-full bg-red-500/80 hover:bg-red-600 text-white backdrop-blur-md border border-white/10 transition-all active:scale-95"
            >
              <X className="w-4 h-4" />
            </button>
          </div>
        </div>

        {/* Transcripts (Subtitle Style) */}
        <AnimatePresence>
          {(userTranscript || assistantTranscript) && (
            <motion.div
              initial={{ opacity: 0, y: 20 }}
              animate={{ opacity: 1, y: 0 }}
              exit={{ opacity: 0, y: 10 }}
              className={`absolute bottom-6 left-4 right-4 space-y-2 pointer-events-none`}
            >
              {userTranscript && (
                <div className="flex justify-end">
                  <div className="bg-white/90 text-gray-800 px-3 py-1.5 rounded-2xl rounded-tr-none text-xs font-medium shadow-lg backdrop-blur-md max-w-[80%]">
                    {userTranscript}
                  </div>
                </div>
              )}
              {assistantTranscript && (
                <div className="flex justify-start">
                  <div className="bg-indigo-600/90 text-white px-3 py-1.5 rounded-2xl rounded-tl-none text-xs font-medium shadow-lg backdrop-blur-md border border-white/10 max-w-[80%]">
                    {assistantTranscript}
                  </div>
                </div>
              )}
            </motion.div>
          )}
        </AnimatePresence>
      </div>

      {/* Control Bar (Glass Bottom) */}
      <div className={`p-4 bg-black/80 backdrop-blur-2xl border-t border-white/5 flex items-center justify-between shrink-0`}>
        <div className="flex items-center space-x-3">
          <button
            onClick={toggleMute}
            disabled={!isActive}
            className={`p-3 rounded-2xl transition-all shadow-lg border ${isMuted ? 'bg-red-500/80 text-white border-red-400' : 'bg-white/10 text-white border-white/10 hover:bg-white/20'} ${!isActive ? 'opacity-30' : 'active:scale-90'}`}
          >
            {isMuted ? <MicOff className="w-5 h-5" /> : <Mic className="w-5 h-5" />}
          </button>

          <button
            onClick={toggleVideo}
            disabled={!isActive}
            className={`p-3 rounded-2xl transition-all shadow-lg border ${!isVideoEnabled ? 'bg-red-500/80 text-white border-red-400' : 'bg-white/10 text-white border-white/10 hover:bg-white/20'} ${!isActive ? 'opacity-30' : 'active:scale-90'}`}
          >
            {isVideoEnabled ? <Video className="w-5 h-5" /> : <VideoOff className="w-5 h-5" />}
          </button>
        </div>

        {/* Start/Stop Interaction */}
        <div className="flex-1 px-4 flex justify-center">
          {!isActive ? (
            <button
              onClick={startCall}
              disabled={isConnecting}
              className={`px-5 py-2.5 bg-indigo-600 hover:bg-indigo-500 text-white rounded-2xl font-bold text-xs flex items-center transition-all shadow-xl shadow-indigo-500/20 active:scale-95 disabled:opacity-50`}
            >
              {isConnecting ? (
                <div className="w-4 h-4 border-2 border-white/30 border-t-white rounded-full animate-spin mr-2" />
              ) : (
                <Camera className="w-4 h-4 mr-2" />
              )}
              {isConnecting ? 'è¿æ¥ä¸­' : 'å¼€å§‹è§‚å¯Ÿ'}
            </button>
          ) : (
            <button
              onClick={stopCall}
              className="px-5 py-2.5 bg-red-500/20 hover:bg-red-500/30 text-red-500 rounded-2xl font-bold text-xs flex items-center transition-all border border-red-500/30 active:scale-95"
            >
              <X className="w-4 h-4 mr-2" />
              ç»“æŸäº’åŠ¨
            </button>
          )}
        </div>

        {/* Small interaction count or metadata could go here */}
        {!isFullScreen && (
          <div className="w-10 flex justify-end opacity-40">
            <GripVertical className="w-4 h-4 text-white" />
          </div>
        )}
      </div>
    </motion.div>
  );
};

export default AIVideoCall;
